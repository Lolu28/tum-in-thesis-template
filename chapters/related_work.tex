\chapter{Related Work}
\label{chapter:Related Work}


\section{Literature}
\subsection{Robotics Systems}
\subsection{Vision-based Segmentation/Recognition}
\subsection{Interactive Perception}

Traditionally, research in passive perception was concentrated on finding a set of features (e.g. color~\cite{Balch_2000_3584}) or higher order features (e.g. those existing in graph cut approaches~\cite{BoykovGraphCut}) in static and segmented images.

In this thesis we take a different approach by creating an interactive scene segmentation and by including robotic arm manipulation into the perception loop. Fitzpatrick~\cite{fitzpatrick_active_vision} and Kenney et al.~\cite{KenneyInteractive} discussed the problem of segmenting rigid objects from a video stream. These video streams presented objects being moved by the robot (pre-planned arm motion) and used a simple Gaussian model of the color values to deduce a possible motion and the graph cut algorithm for the final object segmentation. Their methods are accurate for textured and textureless objects. The difference between their and our approach is that we did not use the pre-planned arm motion. Instead, our arm motion adapts to the scene and enables us to use the 3D data to segment the object aspirants from the background.

The problem of segmenting articulated objects was discussed by Katz et al.~\cite{Katz-WS-MM-ICRA2011}. In this approach, a Lucas-Kanade tracker as well as a set of predictors (short and long distance, color, relative motion, triangulation and fundamental matrix) were used in order to achieve rigid body hypotheses, which took form of a graph. Additionally, they obtained subsequent fixation point on the object which enables segmenting an object based on intensity, color and texture cues. There are some important limitations in this approach. First, the pre-planned arm motion and second, the time needed to break the object hypotheses into subgraphs by using a min-cut algorithm. 
Another approach to interactive segmentation is presented by Bergstrom et al.~\cite{bergstrom11icvs}. Their methodology requires preliminary labelling using a 3D segmentation through fixation whose outcome is a rough initial segmentation. Here, the robot makes an interaction with the scene aiming to disambiguate the hypotheses. Consequently, points in motion space are clustered by using a two component Gaussian mixture model. In this case, the limitation is that the number of objects per scene will never be greater than two.
The approaches described above are relevant to the textured objects only. 

There are some approaches that try to address the problem of planning the perturbations in order to accumulate a sequence of motion cues. Cheng et al.~\cite{chang11interactive} present one of them. In their research they developed a framework for interactive segmentation of individual objects, adding an interaction strategy. It enables scene state update, an iterative object selection, evaluation and manipulation primitive selection. The latter uses a set of heuristic that maximize the push action. Nevertheless, the contribution of this component to the successful segmentation of the objects is still unclear. The manipulation primitive evaluation step makes use of sparse correspondences from the Lukas-Kanade optical flow tracker. Then, it computes a set of transforms which match against a dense point cloud colorwise. The magnitude of the transform motion and the percentage of dense point matches determine the likelihood ratio of a target being a single item or multiple items. The limitation of this framework, with comparison to our work, is lack of estimation of the corner contact points.
Gupta et al.~\cite{gupta11primitives}, on the other hand, present the idea of using a set of motion primitives that consist of pick and place, spread and tumble actions in order to sort cluttered piles of single-color objects. They use Euclidean clustering in the distance and the color space to categorize the scenes as uncluttered, cluttered or piled. Both distance and color space have their limitations. Distance-based clustering depends on correctly selected threshold and color-based clustering relies on stable lighting conditions. This system also presumes that the size of the objects (LEGO bricks) is similar. 

There is a plethora of research that focuses on the estimation of the articulation models for boxes, drawers and similar objects~\cite{Box11Saxena,
  sturm10rss-workshop}. It is usually the case, that these approaches assume the existence of a large, moving plane that can be reliably detected by using e.g. a RANSAC algorithm on the input point cloud and that  unanimously represents the part of the objects that is searched.


\subsection{Interactive Segmentation for Textured Objects}
In our previous work \todo{ref polish thesis and bersch} we developed an interactive segmentation algorithm for textured objects. The idea behind this system is similar to the interactive segmentation system for textureless objects described in this thesis.

Firstly, we extract 2D features which are then tracked while the robot actively induces
motions into a scene using its arm. Then we employ a novel RANSAC-like clustering algorithm in order to assign tracked feature trajectories to the corresponding objects. The number of objects is uknown a priori. The approach was also evaluated on the real robot on a number of scenes.

In those works we also introduced our initial idea of the system that is able to segment objects without texture which is continued as the main subject (together with Interactive Object Recognition and Interactive Perception Library) of this thesis.  

